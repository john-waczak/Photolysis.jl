[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mcm",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "quantum_yields.html",
    "href": "quantum_yields.html",
    "title": "Cross Sections, Quantum Yields, and Photolysis Rates",
    "section": "",
    "text": "Quantum Yields"
  },
  {
    "objectID": "cross_sections.html",
    "href": "cross_sections.html",
    "title": "Cross Sections, Quantum Yields, and Photolysis Rates",
    "section": "",
    "text": "Cross Sections"
  },
  {
    "objectID": "cross_sections/O3.html",
    "href": "cross_sections/O3.html",
    "title": "Cross Sections, Quantum Yields, and Photolysis Rates",
    "section": "",
    "text": "\\(\\mathrm{O_3}\\)\n\nusing Plots, MLPlotRecipes\nusing HDF5\nusing Tables, DataFrames, CSV\nusing MLJ, MLJGaussianProcesses\nusing StatsBase \n\n\ninclude(\"./utils.jl\")\n\ndata_to_df\n\n\n\nh5_path = \"../../data/photolysis_data.h5\" \nspecies = \"O3\" \n\nŒªs, œÉs, T1s, T2s, source_idx, T_units, category, formula, Œª_units, œÉ_units = get_raw_data(h5_path, species)\n\nmin_data_Œª = minimum(Œªs)\nmax_data_Œª = maximum(Œªs)\n\nprintln(min_data_Œª)\nprintln(max_data_Œª)\n\n52.6\n1100.0\n\n\n\n# load in spectrometer wavelengths\nhr4000_df = CSV.File(\"../hr4000_wavelengths.txt\") |> DataFrame ; \n\n\nprintln(nrow(hr4000_df))\nprintln(maximum(hr4000_df.Œª))\nprintln(minimum(hr4000_df.Œª))\n\n3648\n1120.216\n194.249\n\n\n\nŒîŒª = 50 # nm for padding\ndf = data_to_df(Œªs, œÉs, T1s, T2s, source_idx; Œª_lb=minimum(hr4000_df.Œª)-ŒîŒª, Œª_ub=maximum(hr4000_df.Œª)+ŒîŒª)\nprintln(nrow(df))\ndescribe(df)\n\n366284\n\n\n\n4√ó7 DataFrameRowvariablemeanminmedianmaxnmissingeltypeSymbolFloat64RealFloat64RealInt64DataType1Œª565.311144.91539.961100.00Float642œÉ9.07613e-193.4377e-258.0905e-221.41e-170Float643T293.791290.0293.0300.00Float644source_id130.2841175.02490Int64\n\n\n\nnskip = 5\n\np2 = scatter(\n    df.Œª[1:nskip:end],\n    log10.(df.œÉ[1:nskip:end]),\n    zcolor=df.T[1:nskip:end],\n    ms=3, \n    msw=0,\n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"log10(œÉ) [cm¬≤]\",\n    alpha=0.7,\n    rightmargin=10Plots.mm,\n    colorbar_title=\"T [$(T_units)]\",\n    title=\"Absorption Cross Section for O‚ÇÉ\",\n    label=\"\",\n)\n\nsavefig(\"O3_p2.png\")\n\ndisplay(p2)\n\n\n\n\n\np1 = histogram(df.Œª, xlabel=\"Œª\", ylabel=\"counts\", label=\"\", margin=10Plots.mm)\np2 = histogram(df.T, xlabel=\"T\", label=\"\", margin=10Plots.mm)\np3 = histogram(log10.(df.œÉ), xlabel=\"log10(œÉ)\", label=\"\", margin=10Plots.mm)\n#p3 = histogram(df.œÉ, xlabel=\"œÉ\", ylabel=\"counts\")\n\nphist = plot(p1, p2, p3, layout=(1,3), size=(1600, 450), plot_title=\"Data Distribution for O‚ÇÉ\")\n\n\n\n\n\n# load in spectrometer wavelengths\nhr4000_df = CSV.File(\"../hr4000_wavelengths.txt\") |> DataFrame ; \n\n\nprintln(nrow(hr4000_df))\nprintln(maximum(hr4000_df.Œª))\nprintln(minimum(hr4000_df.Œª))\n\n3648\n1120.216\n194.249\n\n\nIt appears that GPR can not handle identical records with different target values, i.e.¬†if \\(x\\_1 = [1.0, 2.0]\\) and \\(x\\_2 = [1.0, 2.0]\\), while \\(y\\_1 = 7.2\\) and \\(y_2 = 7.89\\). To deal with this, let‚Äôs first group the dataframe by temperature, and average across identical wavelength values.\n\ngdfs = groupby(df, :T)\n\nres_dfs = []\n\nfor gdf ‚àà gdfs\n    gdf_by_Œª = groupby(gdf, :Œª)\n    push!(res_dfs, combine(gdf_by_Œª, [:œÉ, :T] .=> mean, renamecols = false))\nend\n\ndf_unique = vcat(res_dfs...)\n\n\n191437√ó3 DataFrame191412 rows omittedRowŒªœÉTFloat64Float64Float641145.955.23e-18298.02148.14.47e-18298.03150.353.69e-18298.04152.652.93e-18298.05155.02.19e-18298.06157.451.63e-18298.07160.01.2e-18298.08162.69.77e-19298.09165.38.66e-19298.010168.18.14e-19298.011170.958.17e-19298.012173.158.57e-19298.013174.658.4e-19298.0‚ãÆ‚ãÆ‚ãÆ‚ãÆ191426721.755.17e-22290.0191427724.784.79e-22290.0191428727.944.51e-22290.0191429731.114.22e-22290.0191430734.133.87e-22290.0191431737.443.74e-22290.0191432740.63.77e-22290.0191433743.93.76e-22290.0191434747.213.66e-22290.0191435749.83.59e-22290.0191436325.1261.647e-20294.09191437253.71.1365e-17297.3\n\n\n\nfunction representative_rand_sample(column::AbstractVector, nbins::Int, npoints::Int)\n    n_per_bin = floor(Int, npoints/nbins)\n    hist = fit(Histogram, column, nbins=nbins)\n    bin_edges = hist.edges[1]\n    \n    idx_out = []\n    \n    # loop over each bin\n    for i ‚àà 1:size(bin_edges, 1)-1\n        bin_idxs = findall(Œæ -> bin_edges[i] < Œæ && Œæ < bin_edges[i+1], column)\n        n_to_sample = minimum([n_per_bin, size(bin_idxs, 1)])\n        idx_res = sample(bin_idxs, n_to_sample, replace=false)\n        push!(idx_out, idx_res)  # sample without replacement\n    end\n\n    return unique(vcat(idx_out...))\nend\n\nŒª_idxs = representative_rand_sample(df_unique.Œª, 1000, 1500)\nœÉ_idxs = representative_rand_sample(log10.(df_unique.œÉ), 500, 2000) \n\n# Œª_idxs = representative_rand_sample(df_unique.Œª, 1250, 1500)\n# œÉ_idxs = representative_rand_sample(log10.(df_unique.œÉ), 750, 2000) \n\n\nidxs_res = shuffle(unique(vcat(Œª_idxs, œÉ_idxs)))\n\n\ndf_sampled = df_unique[idxs_res, :]\n\n\n2387√ó3 DataFrame2362 rows omittedRowŒªœÉTFloat64Float64Float641386.594.21367e-24293.02407.642.12243e-23295.03415.192.91879e-23295.04213.787.43547e-19293.05689.7131.17499e-21293.06364.754.80842e-23295.071028.981.80185e-24293.08894.595.17471e-23293.09260.61.24e-17290.010590.984.48892e-21295.011287.631.86089e-18295.012916.921.64895e-23293.013409.062.56583e-23295.0‚ãÆ‚ãÆ‚ãÆ‚ãÆ2376274.176.07182e-18293.023771039.852.66417e-24293.023781088.51.6595e-24293.02379322.472.14004e-20295.02380596.494.80395e-21293.02381633.563.31589e-21293.02382254.291.28e-17290.02383701.038.4583e-22295.02384372.6993.77e-23293.02385489.538.03712e-22295.02386741.6055.05682e-22293.023871081.371.82854e-24293.0\n\n\n\np1 = histogram(df_sampled.Œª, xlabel=\"Œª\", ylabel=\"counts\", label=\"\", margin=10Plots.mm)\np2 = histogram(df_sampled.T, xlabel=\"T\", label=\"\", margin=10Plots.mm)\np3 = histogram(log10.(df_sampled.œÉ), xlabel=\"log10(œÉ)\", label=\"\", margin=10Plots.mm)\n#p3 = histogram(df.œÉ, xlabel=\"œÉ\", ylabel=\"counts\")\n\nphist = plot(p1, p2, p3, layout=(1,3), size=(1600, 450), plot_title=\"Subsampled Data Distribution for O‚ÇÉ\")\n\n\n\n\n\np = scatter(\n    df_sampled.Œª,\n    log10.(df_sampled.œÉ),\n    zcolor=df_sampled.T,\n    ms=3, \n    msw=0,\n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"log10(œÉ) [cm¬≤]\",\n    alpha=0.7,\n    rightmargin=10Plots.mm,\n    colorbar_title=\"T [$(T_units)]\",\n    title=\"Absorption Cross Section for O‚ÇÉ\",\n    label=\"\",\n)\n\n\n\n\n\nusing KernelFunctions\nusing ParameterHandling\n\n#kernel(Œ∏) = Œ∏.œÉ‚ÇÅ¬≤*(SqExponentialKernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÅ)^2))) + Œ∏.œÉ‚ÇÇ¬≤*(Matern32Kernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÇ)^2)))\n#Œ∏_init = (;œÉ‚ÇÅ¬≤=positive(0.1), ‚Ñì‚ÇÅ=positive(0.1), œÉ‚ÇÇ¬≤=positive(0.1), ‚Ñì‚ÇÇ=positive(0.1),)\n# gpr = GPR(\n    # k = kernel,\n    # Œ∏_init = Œ∏_init, \n    # œÉ¬≤=1e-5\n# )\n# mach = machine(gpr, Xtrain, ytrain) |> fit!\nprintln(nrow(df_sampled))\nXtrain = df_sampled[1:2000, [:Œª, :T]]\nXtest = df_sampled[2001:end, [:Œª, :T]]\n\nytrain = log10.(df_sampled.œÉ[1:2000])\nytest = log10.(df_sampled.œÉ[2001:end])\n\n#gpr = GPR(œÉ¬≤=0.00001)\ngpr = GPR(œÉ¬≤=20.0)\n#gpr = GPR(œÉ¬≤=10.0)\n\nmach = machine(gpr, Xtrain, ytrain) |> fit!\n\n2387\n\n\n[ Info: Training machine(GPR(Œº = 0.0, ‚Ä¶), ‚Ä¶).\n\n\nIter     Function value   Gradient norm \n     0     1.893567e+04     1.091244e+04\n * time: 0.01671600341796875\n     1     1.405405e+04     9.992352e+02\n * time: 6.924190044403076\n     2     4.565267e+03     5.969289e+02\n * time: 11.398995876312256\n     3     4.454063e+03     7.739619e+02\n * time: 13.067230939865112\n     4     4.255704e+03     6.834836e+01\n * time: 14.137372016906738\n     5     4.253254e+03     1.680068e+00\n * time: 15.80565094947815\n     6     4.253250e+03     1.309147e+00\n * time: 17.47168207168579\n     7     4.252584e+03     9.438136e-01\n * time: 20.816890954971313\n     8     4.252583e+03     4.750737e-02\n * time: 22.50261402130127\n     9     4.252583e+03     5.841785e-04\n * time: 24.17035984992981\n    10     4.252583e+03     1.603219e-06\n * time: 25.295099020004272\n    11     4.252583e+03     3.395776e-08\n * time: 26.96492886543274\n    12     4.252583e+03     3.395776e-08\n * time: 28.109287977218628\n    13     4.252583e+03     7.167757e-07\n * time: 30.312039852142334\n    14     4.252583e+03     1.868200e-07\n * time: 34.78383708000183\n    15     4.252583e+03     1.064816e-05\n * time: 37.676944971084595\n    16     4.252583e+03     2.192087e-04\n * time: 44.19379806518555\n    17     3.313514e+03     9.830546e+02\n * time: 53.10497808456421\n    18     3.310122e+03     9.828801e+02\n * time: 58.697805881500244\n    19     2.801403e+03     9.769818e+02\n * time: 60.93287801742554\n    20    -2.844720e+02     1.384003e+03\n * time: 66.63852190971375\n\n\n‚îå Error: Problem fitting the machine machine(GPR(Œº = 0.0, ‚Ä¶), ‚Ä¶). \n‚îî @ MLJBase ~/.julia/packages/MLJBase/uxwHr/src/machines.jl:682\n[ Info: Running type checks... \n[ Info: Type checks okay. \n\n\nLoadError: PosDefException: matrix is not positive definite; Cholesky factorization failed.\n\n\n\ny_pred_train = predict_mean(mach, Xtrain);\ny_pred_test = predict_mean(mach, Xtest);\n\nLoadError: UndefVarError: mach not defined\n\n\nnow let‚Äôs collect some more points in order to evaluate our model using indices other than the ones used during training.\n\np = scatterresult(\n    ytrain, y_pred_train,\n    ytest, y_pred_test,\n    xlabel=\"log10(œÉ) Truth\",\n    ylabel=\"log10(œÉ) Fit\",\n    plot_title=\"O‚ÇÉ GPR Fit\"\n)\n\nsavefig(\"O3_scatter.png\")\nsavefig(\"O3_scatter.pdf\")\n\ndisplay(p)\n\nLoadError: UndefVarError: y_pred_train not defined\n\n\n\np = quantilequantile(\n    ytrain, y_pred_train,\n    ytest, y_pred_test,\n    xlabel=\"log10(œÉ) Truth\",\n    ylabel=\"log10(œÉ) Fit\",\n    title=\"O‚ÇÉ GPR Fit\"\n)\n\nsavefig(\"O3_quantile.png\")\nsavefig(\"O3_quantile.pdf\")\n\ndisplay(p)\n\nLoadError: UndefVarError: y_pred_train not defined\n\n\n\np1 = scatter(\n    Xtrain.Œª,\n    y_pred_train,\n    zcolor=Xtrain.T,\n    ms=3, \n    msw=0,\n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"log10(œÉ) [cm¬≤]\",\n    alpha=0.7,\n    rightmargin=10Plots.mm,\n    colorbar_title=\"T [$(T_units)]\",\n    label=\"Training Data\",\n)\n\nscatter!(\n    Xtest.Œª,\n    y_pred_test,\n    zcolor=Xtest.T,\n    ms=3, \n    msw=0,\n    # markershape=:rect,\n    markershape=:star5,\n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"log10(œÉ) [cm¬≤]\",\n    alpha=0.7,\n    rightmargin=10Plots.mm,\n    colorbar_title=\"T [$(T_units)]\",\n    title=\"Predicted O‚ÇÉ Cross Section\",\n    label=\"Testing Data\",\n)\n\nsavefig(\"predicted_O3_data.png\")\nsavefig(\"predicted_O3_data.pdf\")\n\ndisplay(p1)\n\nLoadError: UndefVarError: y_pred_train not defined\n\n\nFinally, let‚Äôs try prediction at the desired wavelength bins:\n\nfunction predict_logœÉ(T, Œªs, mach)\n    Xout = copy(Œªs)\n    Tout = T\n    Xout[!, :T] = [Tout for _ ‚àà 1:nrow(Œªs)]\n    return predict_mean(mach, Xout)\nend\n\n\np = plot()\n\nTs = 292.0:0.5:300.0\n# cs = cgrad(:thermal, Ts, categorical = true)\ncs = cgrad(:roma, size(Ts,1), categorical = true, rev=true)\ni = 1\nfor T ‚àà Ts\n    logœÉ = predict_logœÉ(T, hr4000_df, mach)\n    plot!(\n        hr4000_df.Œª, logœÉ,\n        linewidth=2,\n        alpha=0.5,\n        color=cs[i],\n        label=\"$(T) K\",\n        legend=:outertopright,\n    )\n    i+=1\nend\n\nxlabel!(\"Œª [nm]\")\nylabel!(\"log10(œÉ) [cm¬≤]\")\ntitle!(\"Predicted Cross Section at Spectrometer Œª's\")\nsavefig(\"O3_œÉ_vs_T.png\")\nsavefig(\"O3_œÉ_vs_T.pdf\")\n\ndisplay(p)\n\nLoadError: UndefVarError: mach not defined"
  },
  {
    "objectID": "cross_sections/H2O2.html",
    "href": "cross_sections/H2O2.html",
    "title": "Cross Sections, Quantum Yields, and Photolysis Rates",
    "section": "",
    "text": "\\(\\mathrm{H_2O_2}\\)"
  },
  {
    "objectID": "cross_sections/O3_old.html",
    "href": "cross_sections/O3_old.html",
    "title": "Cross Sections, Quantum Yields, and Photolysis Rates",
    "section": "",
    "text": "\\(\\mathrm{O_3}\\)\n\nusing Plots, MLPlotRecipes \nusing HDF5 \nusing Tables\nusing MLJ, MLJGaussianProcesses\n\n\nh5_path = \"../../data/photolysis_data.h5\" \nisfile(h5_path)\n\ntrue\n\n\nread in the HDF5 file with our data and identify the cross section data we need:\n\nh5 = h5open(h5_path, \"r\");\n\n\ncross_sections = h5[\"cross-sections\"]\n\n\"O3\" ‚àà keys(cross_sections)\n\nO3_data = cross_sections[\"O3\"]\n\nüìÇ HDF5.Group: /cross-sections/O3 (file: ../../data/photolysis_data.h5)\n‚îú‚îÄ üè∑Ô∏è T1_units\n‚îú‚îÄ üè∑Ô∏è T2_units\n‚îú‚îÄ üè∑Ô∏è category\n‚îú‚îÄ üè∑Ô∏è formula\n‚îú‚îÄ üè∑Ô∏è ŒîœÉ_units\n‚îú‚îÄ üè∑Ô∏è Œª_units\n‚îú‚îÄ üè∑Ô∏è œÉ_units\n‚îú‚îÄ üî¢ T1\n‚îú‚îÄ üî¢ T2\n‚îú‚îÄ üî¢ source_idx\n‚îú‚îÄ üìÇ source_info\n‚îÇ  ‚îú‚îÄ üìÇ 1\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 10\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 100\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 101\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 102\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 103\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 104\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 105\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 106\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 107\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 108\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 109\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 11\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 110\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 111\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 112\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 113\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 114\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 115\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 116\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 117\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 118\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 119\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 12\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 120\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îî‚îÄ (224 more children)\n‚îú‚îÄ üî¢ ŒîœÉ\n‚îú‚îÄ üî¢ Œª\n‚îî‚îÄ üî¢ œÉ\n\n\n\nŒªs = read(O3_data, \"Œª\")\nœÉs = read(O3_data, \"œÉ\")\nT1s = read(O3_data, \"T1\")\nT2s = read(O3_data, \"T2\")\nsource_idx = read(O3_data, \"source_idx\")\n\n\n\nT_units = read_attribute(O3_data, \"T1_units\")\ncategory= read_attribute(O3_data, \"category\")\nformula= read_attribute(O3_data, \"formula\")\nŒª_units = read_attribute(O3_data, \"Œª_units\")\nœÉ_units = read_attribute(O3_data, \"œÉ_units\")\n\nprintln(T_units)\nprintln(category)\nprintln(formula)\nprintln(Œª_units)\nprintln(œÉ_units)\n\nclose(h5)\n\nK\nOzone\nO3\nnm\ncm^2\n\n\n\nprintln(size(Œªs))\nprintln(size(T1s))\nprintln(size(œÉs))\n\n(2591145,)\n(249,)\n(2591145,)\n\n\n\nusing DataFrames\n\n\nfunction generate_data_table(Œªs, œÉs, T1s, T2s, source_idx; œÉ_lb=1e-25, œÉ_ub=1.0, T_lb=290.0, T_ub=305.0, Œª_lb=200.0, Œª_ub=1100.0)\n    Tout = [T1s[source_idx[i]] for i ‚àà 1:size(source_idx, 1)]\n    \n    # we want T2 to be NaN\n    idx = [ i for i  ‚àà 1:size(source_idx,1) if isnan(T2s[source_idx[i]])]\n    Œªout = Œªs[idx]\n    œÉout = œÉs[idx]\n    Tout = Tout[idx]\n    source_out = source_idx[idx]\n\n    # we want T between T_lb and T_ub\n    idx2 = [i for i ‚àà 1:size(Œªout,1) if (T_lb ‚â§ Tout[i] && Tout[i] ‚â§ T_ub)]\n    Œªout = Œªout[idx2]\n    œÉout = œÉout[idx2]\n    Tout = Tout[idx2]\n    source_out = source_out[idx2]\n\n    # we want œÉ to not be NaN and greater than 0.\n    idx3 = [i for i ‚àà 1:size(œÉout,1) if !isnan(œÉout[i]) && (œÉout[i] > œÉ_lb) && (œÉout[i] ‚â§ œÉ_ub)]\n    Œªout = Œªout[idx3]\n    œÉout = œÉout[idx3]\n    Tout = Tout[idx3]\n    source_out = source_out[idx3]\n\n    # we want Œª to be between Œª_lb and Œª_ub\n    idx4 = [i for i ‚àà 1:size(Œªout,1) if (Œª_lb ‚â§ Œªout[i] && Œªout[i] ‚â§ Œª_ub)]\n    Œªout = Œªout[idx4]\n    œÉout = œÉout[idx4]\n    Tout = Tout[idx4]\n    source_out = source_out[idx4]\n   \n    # idxs = [i for i ‚àà 1:size(source_idx, 1) if (T_lb < Temps[i] && Temps[i] < T_ub) && (!isnan(œÉs[i])) && (œÉs[i] ‚â• 0.0) && (Œª_lb ‚â§ Œªs[i] && Œªs[i] ‚â§ Œª_ub) && isnan(T2s[source_idx[i]])]\n\n    # 5. Create table with data containing the good values\n    #data_table = Tables.columntable((; Œª=Œªout, œÉ=œÉout, T=Tout, source_id=source_out))\n    df =  DataFrame(Œª=Œªout, œÉ=œÉout, T=Tout, source_id=source_out)\n    return df\nend\n\n\ndf = generate_data_table(Œªs, œÉs, T1s, T2s, source_idx)\nprintln(nrow(df))\ndescribe(df)\n\n365012\n\n\n\n4√ó7 DataFrameRowvariablemeanminmedianmaxnmissingeltypeSymbolFloat64RealFloat64RealInt64DataType1Œª566.604200.0541.3331100.00Float642œÉ9.09226e-193.4377e-258.00578e-221.41e-170Float643T293.785290.0293.0300.00Float644source_id130.4961175.02490Int64\n\n\n\np = scatter(\n    df.Œª[1:5:end],\n    df.T[1:5:end],\n    zcolor=log10.(df.œÉ[1:5:end]),\n    ms=3,\n    msw=0, \n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"T [$(T_units)]\",\n    label=\"data\", \n    alpha=0.7, \n    rightmargin=10Plots.mm,\n    colorbar_title=\"log10(œÉ) [cm¬≤]\",\n    title=\"Absorption Cross Section Data for O‚ÇÉ\",\n)\n\nsavefig(\"O3_log10œÉ.png\")\n\ndisplay(p)\n\n\n\n\n\np = scatter(\n    df.Œª[1:5:end],\n    df.T[1:5:end],\n    zcolor=df.œÉ[1:5:end],\n    ms=3,\n    msw=0, \n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"T [$(T_units)]\",\n    label=\"data\", \n    alpha=0.7, \n    rightmargin=10Plots.mm,\n    colorbar_title=\"œÉ [cm¬≤]\",\n    title=\"Absorption Cross Section Data for O‚ÇÉ\",\n)\n\nsavefig(\"O3_œÉ.png\")\ndisplay(p)\n\n\n\n\n\np1 = histogram(df.Œª, xlabel=\"Œª\", ylabel=\"counts\", label=\"\", margin=10Plots.mm)\np2 = histogram(df.T, xlabel=\"T\", label=\"\", margin=10Plots.mm)\np3 = histogram(log10.(df.œÉ), xlabel=\"log10(œÉ)\", label=\"\", margin=10Plots.mm)\n#p3 = histogram(df.œÉ, xlabel=\"œÉ\", ylabel=\"counts\")\n\nphist = plot(p1, p2, p3, layout=(1,3), size=(1600, 450))\nsavefig(\"histograms.png\")\ndisplay(phist)\n\n\n\n\nWe can now thik of this as providing our training data. The goal is to learn a function \\(f:(\\lambda, T) \\mapsto \\sigma\\). Our model of choice will be to use a gaussian process.\nFirst let‚Äôs split up the data into training and testing pairs.\n\n\n\n\n\n\nImportant\n\n\n\nWe should think carefully about how to do this. The most important information is probably in regions where there is rapid changes. We can also examine fitting \\(\\log(\\sigma)\\) if \\(\\sigma\\) alone is to sharply peaked‚Ä¶\n\n\n\nn = nrow(df)\ntrain_frac = 0.01\n\nidxs = shuffle(1:n)\nntrain = round(Int, (1.0 - train_frac)*n)\n\nidx_train = idxs[1:ntrain]\nidx_test = idxs[ntrain+1:end]\n\n\ndf_train = df[idx_train, :]\ndf_test = df[idx_test, :]\n\n\n3650√ó4 DataFrame3625 rows omittedRowŒªœÉTsource_idFloat64Float64Float64Int641668.81.73771e-21293.01752852.591.44575e-22293.01763724.05.523e-22295.0534627.9323.746e-21293.02215234.746.18845e-18293.01766599.765.13058e-21295.0487885.134.37375e-23293.01758408.4087.938e-23293.02219800.281.55912e-22295.04810219.241.59597e-18293.017511359.257.69109e-23293.017612803.51.52178e-22295.04813442.361.77009e-22293.0176‚ãÆ‚ãÆ‚ãÆ‚ãÆ‚ãÆ3639364.74.70862e-23295.0483640591.24.4885e-21295.0523641887.024.80926e-23293.01753642711.437.09813e-22293.01763643750.744.15931e-22295.0483644828.41.10054e-22295.0523645657.452.17106e-21293.01753646964.758.73398e-24293.01763647220.091.73649e-18293.01753648957.291.33572e-23293.01763649257.01.09734e-17295.05036501052.213.73944e-24293.0175\n\n\n\nXtrain = df_train[!, [:Œª, :T]]\nytrain = df_train[!, :œÉ]\n\nXtest = df_test[!, [:Œª, :T]]\nytest = df_test[!, :œÉ]\n\n3650-element Vector{Float64}:\n 1.73771e-21\n 1.445749e-22\n 5.523e-22\n 3.746e-21\n 6.188448e-18\n 5.13058e-21\n 4.37375e-23\n 7.938e-23\n 1.55912e-22\n 1.59597e-18\n 7.691088e-23\n 1.52178e-22\n 1.770092e-22\n ‚ãÆ\n 4.70862e-23\n 4.4885e-21\n 4.80926e-23\n 7.098132e-22\n 4.15931e-22\n 1.10054e-22\n 2.17106e-21\n 8.733981e-24\n 1.73649e-18\n 1.335722e-23\n 1.09734e-17\n 3.73944e-24\n\n\n\ngpr = GPR()\n#mach = machine(gpr, Xtrain, ytrain) |> fit!\n\n\nGPR(\n  Œº = 0.0, \n  k = MLJGaussianProcesses.default_kernel, \n  Œ∏_init = (œÉf¬≤ = ParameterHandling.Positive{Float64, typeof(exp), Float64}(-1.490116130486996e-8, exp, 1.4901161193847656e-8), ‚Ñì = ParameterHandling.Positive{Float64, typeof(exp), Float64}(-1.490116130486996e-8, exp, 1.4901161193847656e-8)), \n  œÉ¬≤ = 1.0e-6, \n  optimizer = Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Optim.var\"#19#21\"}(10, LineSearches.InitialStatic{Float64}\n  alpha: Float64 1.0\n  scaled: Bool false\n, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}\n  delta: Float64 0.1\n  sigma: Float64 0.9\n  alphamax: Float64 Inf\n  rho: Float64 5.0\n  epsilon: Float64 1.0e-6\n  gamma: Float64 0.66\n  linesearchmax: Int64 50\n  psi3: Float64 0.1\n  display: Int64 0\n  mayterminate: Base.RefValue{Bool}\n, nothing, Optim.var\"#19#21\"(), Optim.Flat(), true))"
  },
  {
    "objectID": "cross_sections/H2O2_old.html",
    "href": "cross_sections/H2O2_old.html",
    "title": "Cross Sections, Quantum Yields, and Photolysis Rates",
    "section": "",
    "text": "\\(\\mathrm{H_2O_2}\\)\n\nusing Plots, MLPlotRecipes \nusing HDF5 \nusing Tables\nusing MLJ, MLJGaussianProcesses\n\n\nh5_path = \"../../data/photolysis_data.h5\" \nisfile(h5_path)\n\ntrue\n\n\nread in the HDF5 file with our data and identify the cross section data we need:\n\nh5 = h5open(h5_path, \"r\");\n\n\ncross_sections = h5[\"cross-sections\"]\n\n\"H2O2\" ‚àà keys(cross_sections)\n\nH2O2_data = cross_sections[\"H2O2\"]\n\nüìÇ HDF5.Group: /cross-sections/H2O2 (file: ../../data/photolysis_data.h5)\n‚îú‚îÄ üè∑Ô∏è T1_units\n‚îú‚îÄ üè∑Ô∏è T2_units\n‚îú‚îÄ üè∑Ô∏è category\n‚îú‚îÄ üè∑Ô∏è formula\n‚îú‚îÄ üè∑Ô∏è sub-category\n‚îú‚îÄ üè∑Ô∏è ŒîœÉ_units\n‚îú‚îÄ üè∑Ô∏è Œª_units\n‚îú‚îÄ üè∑Ô∏è œÉ_units\n‚îú‚îÄ üî¢ T1\n‚îú‚îÄ üî¢ T2\n‚îú‚îÄ üî¢ source_idx\n‚îú‚îÄ üìÇ source_info\n‚îÇ  ‚îú‚îÄ üìÇ 1\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 10\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 11\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 12\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 13\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 14\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 15\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 16\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 17\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 18\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 19\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 2\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 20\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 21\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 22\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 23\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 24\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 25\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 26\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 27\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 28\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 29\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 3\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 30\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îú‚îÄ üìÇ 4\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è author(year)\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è comments\n‚îÇ  ‚îÇ  ‚îú‚îÄ üè∑Ô∏è doi\n‚îÇ  ‚îÇ  ‚îî‚îÄ üè∑Ô∏è download_url\n‚îÇ  ‚îî‚îÄ (5 more children)\n‚îú‚îÄ üî¢ ŒîœÉ\n‚îú‚îÄ üî¢ Œª\n‚îî‚îÄ üî¢ œÉ\n\n\n\nŒªs = read(H2O2_data, \"Œª\")\nœÉs = read(H2O2_data, \"œÉ\")\nT1s = read(H2O2_data, \"T1\")\nT2s = read(H2O2_data, \"T2\")\nsource_idx = read(H2O2_data, \"source_idx\")\n\n\n\nT_units = read_attribute(H2O2_data, \"T1_units\")\ncategory= read_attribute(H2O2_data, \"category\")\nformula= read_attribute(H2O2_data, \"formula\")\nŒª_units = read_attribute(H2O2_data, \"Œª_units\")\nœÉ_units = read_attribute(H2O2_data, \"œÉ_units\")\n\nprintln(T_units)\nprintln(category)\nprintln(formula)\nprintln(Œª_units)\nprintln(œÉ_units)\n\nclose(h5)\n\nK\nPeroxides\nH2O2\nnm\ncm^2\n\n\n\nprintln(size(Œªs))\nprintln(size(T1s))\nprintln(size(œÉs))\n\n(1164,)\n(30,)\n(1164,)\n\n\n\nusing DataFrames\n\n\nfunction generate_data_table(Œªs, œÉs, T1s, T2s, source_idx; œÉ_lb=1e-25, œÉ_ub=1.0, T_lb=290.0, T_ub=305.0, Œª_lb=200.0, Œª_ub=1100.0)\n    Tout = [T1s[source_idx[i]] for i ‚àà 1:size(source_idx, 1)]\n    \n    # we want T2 to be NaN\n    idx = [ i for i  ‚àà 1:size(source_idx,1) if isnan(T2s[source_idx[i]])]\n    Œªout = Œªs[idx]\n    œÉout = œÉs[idx]\n    Tout = Tout[idx]\n    source_out = source_idx[idx]\n\n    # we want T between T_lb and T_ub\n    idx2 = [i for i ‚àà 1:size(Œªout,1) if (T_lb ‚â§ Tout[i] && Tout[i] ‚â§ T_ub)]\n    Œªout = Œªout[idx2]\n    œÉout = œÉout[idx2]\n    Tout = Tout[idx2]\n    source_out = source_out[idx2]\n\n    # we want œÉ to not be NaN and greater than 0.\n    idx3 = [i for i ‚àà 1:size(œÉout,1) if !isnan(œÉout[i]) && (œÉout[i] > œÉ_lb) && (œÉout[i] ‚â§ œÉ_ub)]\n    Œªout = Œªout[idx3]\n    œÉout = œÉout[idx3]\n    Tout = Tout[idx3]\n    source_out = source_out[idx3]\n\n    # we want Œª to be between Œª_lb and Œª_ub\n    idx4 = [i for i ‚àà 1:size(Œªout,1) if (Œª_lb ‚â§ Œªout[i] && Œªout[i] ‚â§ Œª_ub)]\n    Œªout = Œªout[idx4]\n    œÉout = œÉout[idx4]\n    Tout = Tout[idx4]\n    source_out = source_out[idx4]\n   \n    # idxs = [i for i ‚àà 1:size(source_idx, 1) if (T_lb < Temps[i] && Temps[i] < T_ub) && (!isnan(œÉs[i])) && (œÉs[i] ‚â• 0.0) && (Œª_lb ‚â§ Œªs[i] && Œªs[i] ‚â§ Œª_ub) && isnan(T2s[source_idx[i]])]\n\n    # 5. Create table with data containing the good values\n    #data_table = Tables.columntable((; Œª=Œªout, œÉ=œÉout, T=Tout, source_id=source_out))\n    df =  DataFrame(Œª=Œªout, œÉ=œÉout, T=Tout, source_id=source_out)\n    return df\nend\n\n\ndf = generate_data_table(Œªs, œÉs, T1s, T2s, source_idx)\nprintln(nrow(df))\ndescribe(df)\n\n370\n\n\n\n4√ó7 DataFrameRowvariablemeanminmedianmaxnmissingeltypeSymbolFloat64RealFloat64RealInt64DataType1Œª267.227200.0260.0400.00Float642œÉ1.24797e-192.5e-245.565e-205.47e-190Float643T297.984295.0298.0300.00Float644source_id12.3324111.0290Int64\n\n\n\np = scatter(\n    df.Œª,\n    df.T,\n    zcolor=log10.(df.œÉ),\n    ms=3,\n    msw=0, \n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"T [$(T_units)]\",\n    label=\"data\", \n    alpha=0.7, \n    rightmargin=10Plots.mm,\n    colorbar_title=\"log10(œÉ) [cm¬≤]\",\n    title=\"Absorption Cross Section Data for H‚ÇÇO‚ÇÇ\",\n)\n\n\n\n\n\np = scatter(\n    df.Œª,\n    df.T,\n    zcolor=df.œÉ,\n    ms=3,\n    msw=0, \n    xlabel=\"Œª [$(Œª_units)]\",\n    ylabel=\"T [$(T_units)]\",\n    label=\"data\", \n    alpha=0.7, \n    rightmargin=10Plots.mm,\n    colorbar_title=\"œÉ [cm¬≤]\",\n    title=\"Absorption Cross Section Data for H‚ÇÇO‚ÇÇ\",\n)\n\n\n\n\n\np1 = histogram(df.Œª, xlabel=\"Œª\", ylabel=\"counts\", label=\"\", margin=10Plots.mm)\np2 = histogram(df.T, xlabel=\"T\", label=\"\", margin=10Plots.mm)\np3 = histogram(log10.(df.œÉ), xlabel=\"log10(œÉ)\", label=\"\", margin=10Plots.mm)\n#p3 = histogram(df.œÉ, xlabel=\"œÉ\", ylabel=\"counts\")\n\nphist = plot(p1, p2, p3, layout=(1,3), size=(1600, 450))\n\n\n\n\nWe can now thik of this as providing our training data. The goal is to learn a function \\(f:(\\lambda, T) \\mapsto \\sigma\\). Our model of choice will be to use a gaussian process.\nFirst let‚Äôs split up the data into training and testing pairs.\n\n\n\n\n\n\nImportant\n\n\n\nWe should think carefully about how to do this. The most important information is probably in regions where there is rapid changes. We can also examine fitting \\(\\log(\\sigma)\\) if \\(\\sigma\\) alone is to sharply peaked‚Ä¶\n\n\n\nn = nrow(df)\ntrain_frac = 0.1\n\nidxs = shuffle(1:n)\nntrain = round(Int, (1.0 - train_frac)*n)\n\nidx_train = idxs[1:ntrain]\nidx_test = idxs[ntrain+1:end]\n\n\ndf_train = df[idx_train, :]\ndf_test = df[idx_test, :]\n\n\n37√ó4 DataFrame12 rows omittedRowŒªœÉTsource_idFloat64Float64Float64Int641220.02.58e-19298.062335.01.0e-21298.083340.08.2e-22297.0284255.02.46e-20300.075235.01.56e-19297.0286220.02.45e-19298.0137345.05.0e-22298.088330.01.3e-21296.0119340.08.0e-22300.0710204.04.69e-19298.0411260.05.7e-20296.01212325.02.08e-21297.02813345.05.1e-22300.015‚ãÆ‚ãÆ‚ãÆ‚ãÆ‚ãÆ26245.561.53e-19298.0227207.04.3e-19298.0428340.07.0e-22298.0829290.07.66e-21298.02230315.03.29e-21297.02831270.03.31e-20300.01532345.04.0e-22298.01333277.944.68e-20298.0234340.01.0e-21296.01235370.01.75e-23298.02236345.06.0e-22296.01137218.03.04e-19298.04\n\n\n\nXtrain = df_train[!, [:Œª, :T]];\nytrain = log10.(df_train[!, :œÉ]);\n\nXtest = df_test[!, [:Œª, :T]];\nytest = log10.(df_test[!, :œÉ]);\n\n\nusing Pkg\nPkg.add(\"ParameterHandling\")\n\n   Resolving package versions...\n    Updating `~/gitrepos/ActivePure/Photolysis.jl/mcm/Project.toml`\n  [2412ca09] + ParameterHandling v0.4.6\n  No Changes to `~/gitrepos/ActivePure/Photolysis.jl/mcm/Manifest.toml`\n\n\n\nusing KernelFunctions\nusing ParameterHandling\n\nkernel(Œ∏) = Œ∏.œÉ‚ÇÅ¬≤*(SqExponentialKernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÅ)^2))) + Œ∏.œÉ‚ÇÇ¬≤*(Matern32Kernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÇ)^2)))\nŒ∏_init = (;œÉ‚ÇÅ¬≤=positive(0.1), ‚Ñì‚ÇÅ=positive(0.1), œÉ‚ÇÇ¬≤=positive(0.1), ‚Ñì‚ÇÇ=positive(0.1),)\ngpr = GPR(\n    k = kernel,\n    Œ∏_init = Œ∏_init, \n    œÉ¬≤=1e-7\n)\n# mach = machine(gpr, Xtrain, ytrain) |> fit!\nmach = machine(gpr, df[!, [:Œª, :T]], log10.(df.œÉ)) |> fit!\n\n[ Info: Training machine(GPR(Œº = 0.0, ‚Ä¶), ‚Ä¶).\n\n\nIter     Function value   Gradient norm \n     0     5.520506e+07     4.683357e+07\n * time: 0.00015687942504882812\n     1     8.397008e+04     1.850000e+02\n * time: 0.1980438232421875\n     2     2.910224e+03     8.683632e+06\n * time: 0.7028379440307617\n     3     2.339622e+03     2.052704e+13\n * time: 2.0466439723968506\n     4     2.284220e+03     1.830463e+02\n * time: 2.2037007808685303\n     5     1.831759e+03     1.594123e+02\n * time: 2.2866809368133545\n     6     1.672186e+03     1.028704e+02\n * time: 2.4727489948272705\n     7     1.640279e+03     6.596509e+01\n * time: 2.5251169204711914\n     8     1.624784e+03     8.922078e+00\n * time: 2.5702309608459473\n     9     1.624559e+03     3.020414e-01\n * time: 2.632138967514038\n    10     1.624521e+03     4.003218e+00\n * time: 2.754595994949341\n    11     1.559835e+03     1.059581e+02\n * time: 2.8942248821258545\n    12     1.558517e+03     1.021434e+02\n * time: 3.015133857727051\n    13     1.312760e+03     9.561306e+01\n * time: 3.1111948490142822\n    14     9.228737e+02     6.320437e+01\n * time: 3.2740349769592285\n    15     8.885289e+02     3.601162e+01\n * time: 3.3891518115997314\n    16     8.389134e+02     1.604713e+01\n * time: 3.4401509761810303\n    17     8.335698e+02     3.855661e+00\n * time: 3.5000698566436768\n    18     8.334245e+02     3.626831e-02\n * time: 3.545395851135254\n    19     8.334245e+02     1.353522e-02\n * time: 3.5983259677886963\n    20     4.889816e+02     9.798242e+01\n * time: 3.8875157833099365\n    21     4.871506e+02     9.687293e+01\n * time: 3.931220769882202\n    22     3.474097e+02     5.279476e+01\n * time: 4.0060179233551025\n    23     3.246644e+02     2.937024e+01\n * time: 4.04784083366394\n    24     3.151731e+02     5.276264e+00\n * time: 4.09749698638916\n    25     3.150298e+02     1.377514e+00\n * time: 4.1406848430633545\n    26     3.150150e+02     2.884675e-01\n * time: 4.1958818435668945\n    27     3.149679e+02     1.472008e+00\n * time: 4.3132407665252686\n    28     3.149543e+02     4.499126e-02\n * time: 4.394497871398926\n    29     3.149542e+02     3.037940e-03\n * time: 4.472301959991455\n    30     3.149542e+02     2.376821e-05\n * time: 4.53503680229187\n    31     3.149542e+02     8.836690e-08\n * time: 4.6040449142456055\n    32     3.149542e+02     3.455128e-08\n * time: 4.6613547801971436\n    33     3.149542e+02     3.873630e-09\n * time: 4.705882787704468\n\n\ntrained Machine; caches model-specific representations of data\n  model: GPR(Œº = 0.0, ‚Ä¶)\n  args: \n    1:  Source @412 ‚èé Table{AbstractVector{Continuous}}\n    2:  Source @762 ‚èé AbstractVector{Continuous}\n\n\n\nrpt = report(mach)\n\n(summary = \"L-BFGS\",\n minimizer = [0.08517875349265944, -1.2829398398521916e11, 5.942946238151963, 40.71001341650538, -2.8475008475089973],\n minimum = 314.9541966975367,\n iterations = 33,\n converged = true,)\n\n\n\ny_pred_train = predict_mean(mach, Xtrain)\ny_pred_test = predict_mean(mach, Xtest)\n\n\npy_train = predict(mach, Xtrain)\npy_test = predict(mach, Xtest)\n\npy_train[1]\n\nDistributions.Normal{Float64}(Œº=-21.399818476559005, œÉ=0.10712744012232024)\n\n\n\nscatterresult(\n    ytrain, y_pred_train,\n    ytest, y_pred_test,\n    xlabel=\"log10(œÉ) Truth\",\n    ylabel=\"log10(œÉ) Fit\",\n    plot_title=\"H‚ÇÇO‚ÇÇ GPR Fit\"\n)\n\n\n\n\n\nquantilequantile(\n    ytrain, y_pred_train,\n    ytest, y_pred_test,\n    xlabel=\"log10(œÉ) Truth\",\n    ylabel=\"log10(œÉ) Fit\",\n    title=\"H‚ÇÇO‚ÇÇ Fit Quantile-Quantile\"\n)\n\n\n\n\nNow let‚Äôs plot the resulting function on a grid:\n\nŒª‚ÇÅ = minimum(df.Œª)\nŒª‚ÇÇ = maximum(df.Œª)\nT‚ÇÅ = minimum(df.T)\nT‚ÇÇ = maximum(df.T)\n\nŒîŒª = Œª‚ÇÇ - Œª‚ÇÅ\nŒîT = T‚ÇÇ - T‚ÇÅ\n\nfudge_fac = 0.1\nŒª‚ÇÅ = Œª‚ÇÅ - fudge_fac*ŒîŒª\nŒª‚ÇÇ = Œª‚ÇÇ + fudge_fac*ŒîŒª\nT‚ÇÅ = T‚ÇÅ - fudge_fac*ŒîT\nT‚ÇÇ = T‚ÇÇ + fudge_fac*ŒîT\n\n\nŒªs = range(Œª‚ÇÅ, Œª‚ÇÇ, length=200)\nTs = range(T‚ÇÅ, T‚ÇÇ, length=50)\n\n# resulting shape should be reshaped to 500 by 50\nŒª_grid = [Œª for Œª‚ààŒªs, T‚ààTs]\nT_grid = [T for Œª‚ààŒªs, T‚ààTs]\ndf_grid = DataFrame(Œª=vcat(Œª_grid...), T=vcat(T_grid...))\nœÉ_grid = reshape(predict_mean(mach, df_grid),(200,50))\n\nheatmap(Œªs, Ts, œÉ_grid)\n\nscatter!(\n    df.Œª,\n    df.T,\n    zcolor=log10.(df.œÉ),\n    ms=4,\n    label=\"data\", \n    rightmargin=10Plots.mm,\n    colorbar_title=\"œÉ [cm¬≤]\",\n)\n\n298.0\n\n\n\nŒªs = range(Œª‚ÇÅ, Œª‚ÇÇ, length=500)\nTs = [298.0 for _ ‚àà 1:500]\ndf_pred = DataFrame(Œª=Œªs, T=Ts)\nœÉ_preds = predict_mean(mach, df_pred)\n\nplot(Œªs, œÉ_preds)\n\n\n\n\n\nfunction make_training_data(n, ŒΩ)\n    xs = reshape(collect(range(0.0, stop=1.0, length=500)), (1,500))\n\n    y(x) = (exp(-x/(0.5)^2) * sin(2œÄ*ŒΩ*x)) + (0.3)^2*(rand()-0.5)\n    ytruth(x) = exp(-x/(0.5)^2) * sin(2œÄ*ŒΩ*x)\n\n    X = Tables.table(rand(1,n)', header=[:x])\n    Xtrue = Tables.table(xs', header=[:x])\n\n    y = y.(X.x)\n    ytrue = ytruth.(Xtrue.x)\n\n    return X, y, Xtrue, ytrue\nend\n\nX, y, Xtrue, ytrue = make_training_data(50, 10)\n\n(Tables.MatrixTable{LinearAlgebra.Adjoint{Float64, Matrix{Float64}}} with 50 rows, 1 columns, and schema:\n :x  Float64, [-0.11910037399566864, 0.01220942201251572, -0.010091656163291975, 0.02066646335009669, -0.011549536452583477, 0.8137673436519305, -0.039571239673889064, -0.011172731423395085, -0.144878198731118, -0.12315261399469685  ‚Ä¶  -0.033534805230887144, 0.14887469603148903, 0.890109273286779, -0.04974330747314241, 0.2781718602943487, -0.042666066500645396, -0.12454136396033408, -0.06221610591174015, 0.1735472693012275, 0.0501742130486802], Tables.MatrixTable{LinearAlgebra.Adjoint{Float64, Matrix{Float64}}} with 500 rows, 1 columns, and schema:\n :x  Float64, [0.0, 0.12458042096548765, 0.24521471376453977, 0.3600631014574817, 0.46740631751315176, 0.5656708039301793, 0.6534512106157103, 0.7295298841027695, 0.7928930861297541, 0.8427437383060459  ‚Ä¶  -0.017831231548023147, -0.016509647442768692, -0.01494870660243864, -0.013176833587402128, -0.011225327522356849, -0.009127822756544184, -0.006919721272661151, -0.004637606245326371, -0.002318646297738392, -4.4860377078854197e-17])\n\n\n\nkernel(Œ∏) = Œ∏.œÉ‚ÇÅ¬≤*(SqExponentialKernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÅ)^2))) + Œ∏.œÉ‚ÇÇ¬≤*(Matern32Kernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÇ)^2)))\nŒ∏_init = (;œÉ‚ÇÅ¬≤=positive(0.1), ‚Ñì‚ÇÅ=positive(0.1), œÉ‚ÇÇ¬≤=positive(0.1), ‚Ñì‚ÇÇ=positive(0.1),)\ngpr = GPR(\n    k = kernel,\n    Œ∏_init = Œ∏_init, \n    œÉ¬≤=1e-7\n)\n# mach = machine(gpr, Xtrain, ytrain) |> fit!\nmach = machine(gpr, X, y) |> fit!\n\n[ Info: Training machine(GPR(Œº = 0.0, ‚Ä¶), ‚Ä¶).\n\n\nIter     Function value   Gradient norm \n     0     6.176849e+02     3.294959e+03\n * time: 0.0001609325408935547\n     1     4.245610e+02     2.500000e+01\n * time: 0.01802802085876465\n     2     1.536238e-01     9.276824e+00\n * time: 0.023598909378051758\n     3    -1.838432e+00     1.642444e+01\n * time: 0.028696060180664062\n     4    -2.222085e+00     3.646697e+00\n * time: 0.031058073043823242\n     5    -2.409770e+00     1.895024e+00\n * time: 0.03342390060424805\n     6    -2.424902e+00     4.591384e-02\n * time: 0.03683209419250488\n     7    -2.424945e+00     6.948281e-03\n * time: 0.04055190086364746\n     8    -2.424955e+00     4.642882e-02\n * time: 0.04716300964355469\n     9    -3.911795e+00     1.691929e+01\n * time: 0.06146502494812012\n    10    -3.911854e+00     1.693188e+01\n * time: 0.06484293937683105\n    11    -2.544498e+01     1.811944e+01\n * time: 0.07523202896118164\n    12    -2.773278e+01     1.382678e+01\n * time: 0.08808112144470215\n    13    -3.026212e+01     4.678491e+00\n * time: 0.09667491912841797\n    14    -3.213040e+01     5.934352e+00\n * time: 0.09993100166320801\n    15    -3.418021e+01     5.000502e+00\n * time: 0.10272097587585449\n    16    -3.484923e+01     1.268289e+01\n * time: 0.10554909706115723\n    17    -3.518251e+01     4.125281e+00\n * time: 0.10827898979187012\n    18    -3.540297e+01     2.758169e-01\n * time: 0.11300206184387207\n    19    -3.540563e+01     1.548509e-01\n * time: 0.11755704879760742\n    20    -3.540565e+01     1.663166e-03\n * time: 0.12055611610412598\n    21    -3.540565e+01     9.652292e-06\n * time: 0.12480306625366211\n    22    -3.540565e+01     5.053648e-08\n * time: 0.12941789627075195\n    23    -3.540565e+01     6.864558e-11\n * time: 0.1333160400390625\n\n\ntrained Machine; caches model-specific representations of data\n  model: GPR(Œº = 0.0, ‚Ä¶)\n  args: \n    1:  Source @492 ‚èé Table{AbstractVector{Continuous}}\n    2:  Source @084 ‚èé AbstractVector{Continuous}\n\n\n\ny_pred = predict_mean(mach, Xtrue)\n\n500-element Vector{Float64}:\n  0.5608180743428964\n  0.6071206663803306\n  0.6529973819201168\n  0.6977092492488189\n  0.7404547349060291\n  0.7803823497474104\n  0.8166060889345779\n  0.8482234990255315\n  0.8743360494648164\n  0.8940713721610013\n  0.9066068265312588\n  0.9111937534571365\n  0.9071817048894731\n  ‚ãÆ\n -0.06438038355570742\n -0.06776164321695946\n -0.07041055912915144\n -0.0723032111728047\n -0.07343523548509083\n -0.07382060128312681\n -0.07348987474542858\n -0.07248807840635572\n -0.0708722612638966\n -0.06870889576551893\n -0.06607121353515381\n -0.0630365828885893\n\n\n\nplot(Xtrue.x, y_pred)\nscatter!(X.x, y)\n\n\n\n\n\nn=1000\nxs = (rand(n,2) .- 0.5)\nx‚ÇÅ = xs[:,1]\nx‚ÇÇ = xs[:,2]\ny = x‚ÇÅ.^5 .+ x‚ÇÇ.^4 .- x‚ÇÅ.^4 .- x‚ÇÇ.^3 \n\nXtrain = Tables.table(xs[1:Int(0.9*n), :], header=[:x‚ÇÅ, :x‚ÇÇ])\nXtest = Tables.table(xs[Int(0.9*n)+1:end, :], header=[:x‚ÇÅ, :x‚ÇÇ])\n\nytrain = y[1:Int(0.9*n)]\nytest = y[Int(0.9*n)+1:end]\n\nscatter(Xtrain.x‚ÇÅ, Xtrain.x‚ÇÇ, ytrain, ms=3, label=\"training points\")\nscatter!(Xtest.x‚ÇÅ, Xtest.x‚ÇÇ, ytest, color=:red, ms=3, label=\"testing points\")\n\n\n\n\n\nkernel(Œ∏) = Œ∏.œÉ‚ÇÅ¬≤*(SqExponentialKernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÅ)^2))) + Œ∏.œÉ‚ÇÇ¬≤*(Matern32Kernel() ‚àò ScaleTransform(1/(2(Œ∏.‚Ñì‚ÇÇ)^2)))\nŒ∏_init = (;œÉ‚ÇÅ¬≤=positive(0.1), ‚Ñì‚ÇÅ=positive(0.1), œÉ‚ÇÇ¬≤=positive(0.1), ‚Ñì‚ÇÇ=positive(0.1),)\ngpr = GPR(\n    k = kernel,\n    Œ∏_init = Œ∏_init, \n#    œÉ¬≤=1e-7\n)\n# mach = machine(gpr, Xtrain, ytrain) |> fit!\nmach = machine(gpr, Xtrain, ytrain) |> fit!\n\n[ Info: Training machine(GPR(Œº = 0.0, ‚Ä¶), ‚Ä¶).\n\n\nIter     Function value   Gradient norm \n     0    -1.670727e+02     5.199854e+02\n * time: 0.00019097328186035156\n     1    -4.734137e+03     1.503170e+03\n * time: 4.420762062072754\n     2    -4.840642e+03     9.308025e+02\n * time: 5.104015111923218\n     3    -5.098898e+03     8.038598e+02\n * time: 5.796343088150024\n     4    -5.346684e+03     3.970594e+02\n * time: 6.482567071914673\n     5    -5.896281e+03     1.717814e+03\n * time: 7.4011549949646\n     6    -6.727720e+03     9.644671e+02\n * time: 8.08535099029541\n     7    -6.864112e+03     4.600626e+01\n * time: 8.542866945266724\n     8    -6.886448e+03     4.059468e+02\n * time: 9.247071981430054\n     9    -6.898714e+03     7.109971e+01\n * time: 9.94740605354309\n    10    -6.906918e+03     2.015111e+02\n * time: 10.866995096206665\n    11    -6.913086e+03     1.368285e+02\n * time: 11.548546075820923\n    12    -6.950506e+03     2.913849e+02\n * time: 12.473842144012451\n    13    -7.001777e+03     4.041452e+02\n * time: 13.156044960021973\n    14    -7.046138e+03     1.589057e+02\n * time: 13.838634014129639\n    15    -7.050020e+03     3.377373e+01\n * time: 14.578689098358154\n    16    -7.050116e+03     1.424288e+01\n * time: 15.060181140899658\n    17    -7.050119e+03     8.910666e-01\n * time: 16.643229007720947\n    18    -7.050112e+03     8.341030e-01\n * time: 20.30194902420044\n    19    -7.050112e+03     1.179394e+00\n * time: 26.873029947280884\n    20    -7.050107e+03     2.248200e-01\n * time: 27.352442979812622\n    21    -7.050115e+03     1.044133e+00\n * time: 27.810850143432617\n    22    -7.050117e+03     4.746199e-01\n * time: 32.38437104225159\n    23    -7.050121e+03     8.571094e-01\n * time: 34.8969349861145\n    24    -7.050125e+03     2.832218e-01\n * time: 36.723212003707886\n\n\ntrained Machine; caches model-specific representations of data\n  model: GPR(Œº = 0.0, ‚Ä¶)\n  args: \n    1:  Source @728 ‚èé Table{AbstractVector{Continuous}}\n    2:  Source @679 ‚èé AbstractVector{Continuous}\n\n\n\ny_pred_train = predict_mean(mach, Xtrain)\ny_pred_test = predict_mean(mach, Xtest)\n\n100-element Vector{Float64}:\n -2.8878450393676758e-5\n  0.0344734862446785\n  0.09831034205853939\n -0.01759042777121067\n -0.06359002739191055\n -0.01516430452466011\n  0.0030932649970054626\n -0.0002354402095079422\n -0.014944754540920258\n -0.05883212573826313\n -0.08973219990730286\n -0.00040311552584171295\n -0.01130409725010395\n  ‚ãÆ\n -1.8864870071411133e-5\n  0.0848623551428318\n -0.014372158795595169\n  0.001810908317565918\n -0.017009228467941284\n -0.0011161155998706818\n -0.03888287954032421\n -0.020225761458277702\n  0.0007748045027256012\n  0.0014734435826539993\n -0.04117823205888271\n  0.07993144396459684\n\n\n\nscatterresult(\n    ytrain, y_pred_train,\n    ytest, y_pred_test,\n    xlabel=\"Truth\",\n    ylabel=\"Fit\",\n    plot_title=\"Fit\"\n)\n\n\n\n\nOkay, so this confirms that my GPR algorithm"
  }
]